{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for CECP CoP21 website\n",
    "File locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GDX_DIR = 'gdx'\n",
    "OUT_DIR = '../cecp-cop21-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run C-REM\n",
    "Run the next cell will run the model eight times, which takes a *very long time*. The commands are provided for illustration.\n",
    "\n",
    "Currently, separate commits of C-REM must be used to run the base and 'less-GDP' cases.\n",
    "\n",
    "See [issue #35](https://github.com/mit-jp/crem/issues/35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process is terminated.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# C-REM runs\n",
    "crem gdx/result_urban_exo -- --case=default\n",
    "crem gdx/result_cint_n_3 -- --case=cint_n --cint_n_rate=3\n",
    "crem gdx/result_cint_n_4 -- --case=cint_n --cint_n_rate=4\n",
    "crem gdx/result_cint_n_5 -- --case=cint_n --cint_n_rate=5\n",
    "# Low-growth cases\n",
    "crem gdx/result_urban_exo_lessGDP -- --case=default\n",
    "crem gdx/result_cint_n_3_lessGDP -- --case=cint_n --cint_n_rate=3\n",
    "crem gdx/result_cint_n_4_lessGDP -- --case=cint_n --cint_n_rate=4\n",
    "crem gdx/result_cint_n_5_lessGDP -- --case=cint_n --cint_n_rate=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the GDX files\n",
    "Some of the quantities used below are stored in the GAMS parameters `report(*,*,*)` and `egyreport2(*,*,*,*)`, which pyGDX cannot handle. The cell below runs the simple GAMS script `pre.gms` to produce a new file named `*foo*_extra.gdx` with the pyGDX-friendly variables `ptcarb_t(t)`, `pe_t(e,r,t)` and `cons_t(r,t)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gams pre.gms --file=gdx/result_urban_exo\n",
    "gams pre.gms --file=gdx/result_cint_n_3\n",
    "gams pre.gms --file=gdx/result_cint_n_4\n",
    "gams pre.gms --file=gdx/result_cint_n_5\n",
    "gams pre.gms --file=gdx/result_urban_exo_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_3_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_4_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_5_lessGDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the GDX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all the GDX files\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from os import makedirs as mkdir\n",
    "from os.path import join\n",
    "\n",
    "import gdx\n",
    "from numpy import nan\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import xray\n",
    "\n",
    "FILES = [\n",
    "    ('bau', 'result_urban_exo.gdx'),\n",
    "    ('3', 'result_cint_n_3.gdx'),\n",
    "    ('4', 'result_cint_n_4.gdx'),\n",
    "    ('5', 'result_cint_n_5.gdx'),\n",
    "    ('bau_lo', 'result_urban_exo_lessGDP.gdx'),\n",
    "    ('3_lo', 'result_cint_n_3_lessGDP.gdx'),\n",
    "    ('4_lo', 'result_cint_n_4_lessGDP.gdx'),\n",
    "    ('5_lo', 'result_cint_n_5_lessGDP.gdx'),\n",
    "    ]\n",
    "\n",
    "raw = OrderedDict()\n",
    "extra = dict()\n",
    "for case, fn in FILES:\n",
    "    raw[case] = gdx.File('gdx/' + fn)\n",
    "    extra[case] = gdx.File('gdx/' + fn.replace('.gdx', '_extra.gdx'))\n",
    "\n",
    "CREM = raw['bau']\n",
    "cases = pd.Index(raw.keys(), name='case')\n",
    "time = pd.Index(filter(lambda t: int(t) <= 2030, CREM.set('t')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List all the parameters available in each file\n",
    "#CREM.parameters()\n",
    "\n",
    "# Temporary container for read-in data\n",
    "arrays = {}\n",
    "\n",
    "def label(variable, desc, unit_long, unit_short):\n",
    "    \"\"\"Add some descriptive attributes to an xray.DataArray.\"\"\"\n",
    "    arrays[variable].attrs.update({'desc': desc, 'unit_long': unit_long,\n",
    "                                   'unit_short': unit_short})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GDP\n",
    "temp = [raw[case].extract('gdp_ref') for case in cases]\n",
    "arrays['GDP'] = xray.concat(temp, dim=cases).sel(rs=CREM.set('r')) \\\n",
    "                    .rename({'rs': 'r'})\n",
    "label('GDP', 'Gross domestic product',\n",
    "      'billions of U.S. dollars, constant at 2007', '10⁹ USD')\n",
    "\n",
    "arrays['GDP_aagr'] = ((arrays['GDP'][:,:,1:].values / arrays['GDP'][:,:,:-1])\n",
    "                      ** (1 / CREM.extract('lp')) - 1) * 100\n",
    "label('GDP_aagr', 'Gross domestic product, average annual growth rate',\n",
    "      'percent', '%')\n",
    "\n",
    "arrays['GDP_delta'] = (arrays['GDP'] / arrays['GDP'].sel(case='bau') - 1) * 100\n",
    "label('GDP_delta', 'Change in gross domestic product relative to BAU',\n",
    "      'percent', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CO2 emissions\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('sectem').sum('g') +\n",
    "        raw[case].extract('houem'))\n",
    "arrays['CO2_emi'] = xray.concat(temp, dim=cases)\n",
    "label('CO2_emi', 'Annual CO₂ emissions',\n",
    "      'millions of tonnes of CO₂', 'Mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Air pollutant emissions\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('urban').sum('*'))\n",
    "temp = xray.concat(temp, dim=cases).sel(rs=CREM.set('r')).rename({'rs': 'r'})\n",
    "for u in temp['urb']:\n",
    "    if u in ['PM10', 'PM25']:\n",
    "        continue\n",
    "    var_name = '{}_emi'.format(u.values)\n",
    "    arrays[var_name] = temp.sel(urb=u).drop('urb')\n",
    "    u_fancy = str(u.values).translate({'2': '₂', '3': '₃'})\n",
    "    label(var_name, 'Annual {} emissions'.format(u_fancy),\n",
    "          'millions of tonnes of ' + str(u_fancy), 'Mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CO₂ price\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('ptcarb_t'))\n",
    "arrays['CO2_price'] = xray.concat(temp, dim=cases)\n",
    "label('CO2_price', 'Price of CO₂ emissions permit',\n",
    "      '2007 US dollars per tonne CO₂', '2007 USD/t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consumption\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('cons_t'))\n",
    "arrays['cons'] = xray.concat(temp, dim=cases)\n",
    "label('cons', 'Household consumption',\n",
    "      'billions of U.S. dollars, constant at 2007', '10⁹ USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Primary energy\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('pe_t'))\n",
    "temp = xray.concat(temp, dim=cases)\n",
    "temp = temp.where(temp < 1e300).fillna(0)\n",
    "e_name = {\n",
    "    'COL': 'Coal',\n",
    "    'GAS': 'Natural gas',\n",
    "    'OIL': 'Crude oil',\n",
    "    'NUC': 'Nuclear',\n",
    "    'WND': 'Wind',\n",
    "    'SOL': 'Solar',\n",
    "    'HYD': 'Hydroelectricity',\n",
    "    }\n",
    "for ener in temp['e']:\n",
    "    var_name = '{}_energy'.format(ener.values)\n",
    "    # Convert non-fossil electrical energy to the raw quantity of coal needed\n",
    "    # to generate such amount of electricity:\n",
    "    arrays[var_name] = temp.sel(e=ener).drop('e') * (1. if ener in\n",
    "                                                     ['COL', 'GAS', 'OIL'] else\n",
    "                                                     0.356 / 0.12)\n",
    "    label(var_name, 'Primary energy from {}'.format(e_name[str(ener.values)]),\n",
    "          'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "# Sums and shares \n",
    "arrays['energy_fossil'] = temp.sel(e=['COL', 'GAS', 'OIL']).sum('e')\n",
    "label('energy_fossil', 'Primary energy from fossil fuels',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['energy_nonfossil'] = (temp.sel(e=['NUC', 'WND', 'SOL', 'HYD']).sum('e')\n",
    "                              * 0.356 / 0.12)\n",
    "label('energy_nonfossil', 'Primary energy from non-fossil sources',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['energy_total'] = arrays['energy_fossil'] + arrays['energy_nonfossil']\n",
    "label('energy_total', 'Primary energy, total',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['penergy_nonfossil_share'] = (arrays['energy_nonfossil'] /\n",
    "    arrays['energy_total']) * 100\n",
    "label('penergy_nonfossil_share',\n",
    "      'Share of non-fossil sources in final energy',\n",
    "      'percent', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Reported share of NHW\n",
    "temp1 = []\n",
    "temp2 = []\n",
    "for case in cases:\n",
    "    temp1.append(extra[case].extract('nhw_share'))\n",
    "    temp2.append(extra[case].extract('nhw_share_CN')) \n",
    "arrays['energy_nonfossil_share'] = 100 * xray.concat(temp1, dim=cases)\n",
    "label('energy_nonfossil_share',\n",
    "      'Share of non-fossil sources in final energy',\n",
    "      'percent', '%')\n",
    "nhw_share = 100 * xray.concat(temp2, dim=cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Population\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('pop2007').sel(g='c') *\n",
    "                raw[case].extract('pop') * 1e-2)\n",
    "arrays['pop'] = xray.concat(temp, dim=cases).drop('g').sel(rs=CREM.set('r')) \\\n",
    "                    .rename({'rs': 'r'})\n",
    "label('pop', 'Population', 'millions', '10⁶')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Share of coal in provincial GDP\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw['bau'].extract('sect_prod'))\n",
    "sect_prod = xray.concat(temp, dim=cases).sel(rs=CREM.set('r'), g='COL') \\\n",
    "                .drop('g').rename({'rs': 'r'})\n",
    "arrays['COL_share'] = (sect_prod / arrays['GDP']) * 100\n",
    "label('COL_share', 'Share of coal production in provincial GDP',\n",
    "      'percent', '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1. PM2.5 concentrations & population-weighted exposure\n",
    "**Note:** these are contained in a separate XLSX file, pm.xslx."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open the workbook and worksheet\n",
    "wb = load_workbook('pm.xlsx', read_only=True)\n",
    "\n",
    "cols = {\n",
    "    None: None,\n",
    "    2010: ('bau', '2010'),\n",
    "    '2030_BAU': ('bau', '2030'),\n",
    "    '2030_p2': ('2', '2030'),\n",
    "    '2030_p3': ('3', '2030'),\n",
    "    '2030_p4': ('4', '2030'),\n",
    "    '2030_p5': ('5', '2030'),\n",
    "    '2030_p6': ('6', '2030'),\n",
    "    }\n",
    "pm_extra = {}\n",
    "for ws in wb:\n",
    "    # Read the table in to a list of lists\n",
    "    temp = []\n",
    "    for r, row in enumerate(ws.rows):\n",
    "        if r == 0:\n",
    "            temp.append([cols[cell.value] for cell in row])\n",
    "        else:\n",
    "            temp.append([cell.value for cell in row])\n",
    "\n",
    "    # Convert to a pandas.DataFrame\n",
    "    df = pd.DataFrame(temp).set_index(0).dropna(axis=(0, 1), how='all')\n",
    "    df.columns = pd.MultiIndex.from_tuples(df.iloc[0,:], names=['case', 't'])\n",
    "    df.drop(None, inplace=True)\n",
    "    df.index.name = 'r'\n",
    "    df.dropna(axis=(0, 1), how='all', inplace=True)\n",
    "    df = df.stack(['case', 't']).swaplevel('case', 'r')\n",
    "\n",
    "    # Convert to an xray.DataArray\n",
    "    da = xray.DataArray.from_series(df)\n",
    "    # Fill in 2010 values across cases\n",
    "    da.loc[:,:,'2010'] = da.loc['bau',:,'2010']\n",
    "\n",
    "    if ws.title == 'prv_actual_average':\n",
    "        arrays['PM25_conc'] = da.drop(['2', '6'], dim='case')\n",
    "        label('PM25_conc', 'Province-wide average PM2.5',\n",
    "              'micrograms per cubic metre', 'μg/m³')\n",
    "    elif ws.title == 'prv_pop_average':\n",
    "        arrays['PM25_exposure'] = da.drop(['2', '6'], dim='case')\n",
    "        label('PM25_exposure', 'Population-weighted exposure to PM2.5',\n",
    "              'micrograms per cubic metre', 'μg/m³')\n",
    "    else:\n",
    "        pm_extra[ws.title] = da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame([\n",
    "    ['bau', '2010', 66.37],\n",
    "    ['bau', '2030', 84.78],\n",
    "    ['3'  , '2030', 78.64],\n",
    "    ['4'  , '2030', 71.23],\n",
    "    ['5'  , '2030', 60.87]],\n",
    "    columns=['case', 't', 'value']).set_index(['case', 't'])\n",
    "da = xray.DataArray.from_series(df['value'])\n",
    "# Fill in 2010 values across cases\n",
    "da.loc[:,'2010'] = da.loc['bau','2010']\n",
    "PM25_exposed_frac = da\n",
    "\n",
    "# Placeholder value at regional level\n",
    "arrays['PM25_exposed_frac'] = xray.DataArray([nan] * len(time), coords=[time],\n",
    "                                             dims='t')\n",
    "label('PM25_exposed_frac', 'Population exposed to PM2.5 concentrations greater'\n",
    "      ' than 35 μg/m³', 'percent', '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. Finish preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all variables into a single xray.Dataset and truncate time\n",
    "data = xray.Dataset(arrays).sel(t=time)\n",
    "\n",
    "data['scenarios'] = xray.DataArray((\n",
    "    'BAU: Business-as-usual',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 3%/year from BAU',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 4%/year from BAU',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 5%/year from BAU',\n",
    "    'LO: BAU with 1% lower annual GDP growth',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 3%/year from LO',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 4%/year from LO',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 5%/year from LO',\n",
    "    ), coords={'case': cases}, dims='case')\n",
    "\n",
    "for var in [data.PM25_exposure, data.PM25_conc]:\n",
    "    # interpolate PM data for missing years\n",
    "    var.loc[:,:,'2007'] = var.loc[:,:,'2010']\n",
    "    increment = (var.loc[:,:,'2030'] - var.loc[:,:,'2010']) / 4\n",
    "    var.loc[:,:,'2015'] = var.loc[:,:,'2010'] + increment\n",
    "    var.loc[:,:,'2020'] = var.loc[:,:,'2010'] + 2 * increment\n",
    "    var.loc[:,:,'2025'] = var.loc[:,:,'2010'] + 3 * increment\n",
    "    # fill in PM data for missing cases\n",
    "    var.loc['bau_lo',:,:] = var.loc['bau',:,:] * 0.9\n",
    "    var.loc['3_lo',:,:] = var.loc['3',:,:] * 0.9\n",
    "    var.loc['4_lo',:,:] = var.loc['4',:,:] * 0.9\n",
    "    var.loc['5_lo',:,:] = var.loc['5',:,:] * 0.9\n",
    "\n",
    "# Construct data for low-ammonia cases\n",
    "# N.B. the NH₃ cases do not appear on the final website, so these lines simply\n",
    "#      copy data from the other cases.\n",
    "base_cases = [str(name.values) for name in data['case']]\n",
    "nh3_cases = [name + '_nh3' for name in base_cases]\n",
    "d = xray.Dataset(coords={'case': nh3_cases})\n",
    "data.merge(d, join='outer', inplace=True)\n",
    "# fill in PM data for missing cases\n",
    "for nh3_case, base_case in zip(nh3_cases, base_cases):\n",
    "    data.PM25_conc.loc[nh3_case,:,:] = data.PM25_conc.loc[base_case,:,:]\n",
    "\n",
    "\n",
    "# Compute national totals and averages\n",
    "national = data.sum('r')\n",
    "national['penergy_nonfossil_share'] = (national['energy_nonfossil'] /\n",
    "                                       national['energy_total']) * 100\n",
    "national['energy_nonfossil_share'] = nhw_share\n",
    "national['PM25_exposed_frac'] = PM25_exposed_frac\n",
    "# FIXME use a proper national average\n",
    "# Unweighted average across provincial averages\n",
    "national['PM25_exposure'] = data.PM25_exposure.mean(dim='r')\n",
    "national['PM25_conc'] = data.PM25_conc.mean(dim='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dimension info:\n",
      "  (None)\n"
     ]
    }
   ],
   "source": [
    "# Output a file with scenario information\n",
    "data['scenarios'].to_dataframe().to_csv(join(OUT_DIR, 'scenarios.csv'),\n",
    "                                        header=['description'],\n",
    "                                        quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Output a file with variable information\n",
    "var_info = pd.DataFrame(index=[d for d in data.data_vars if d != 'scenarios'],\n",
    "                        columns=['desc', 'unit_long', 'unit_short'],\n",
    "                        dtype=str)\n",
    "print('Missing dimension info:')\n",
    "none_missing = True\n",
    "for name, _ in var_info.iterrows():\n",
    "    try:\n",
    "        row = [data[name].attrs[k] for k in var_info.columns]\n",
    "    except KeyError:\n",
    "        print('  ', name)\n",
    "        none_missing = False\n",
    "        continue\n",
    "    var_info.loc[name,:] = row\n",
    "if none_missing:\n",
    "    print('  (None)')\n",
    "var_info.to_csv(join(OUT_DIR, 'variables.csv'), index_label='Variable',\n",
    "                quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Create directories\n",
    "for r in CREM.set('r'):\n",
    "    mkdir(join(OUT_DIR, r), exist_ok=True)\n",
    "mkdir(join(OUT_DIR, 'national'), exist_ok=True)\n",
    "\n",
    "# Serialize to CSV\n",
    "for c in map(lambda x: x.values, data.case):\n",
    "    # Provincial data\n",
    "    for r in CREM.set('r'):\n",
    "        data.sel(case=c, r=r).drop(['case', 'r', 'scenarios']).to_dataframe() \\\n",
    "            .to_csv(join(OUT_DIR, r, '{}.csv'.format(c)))\n",
    "    # National data\n",
    "    national.sel(case=c).drop(['case', 'scenarios']).to_dataframe() \\\n",
    "            .to_csv(join(OUT_DIR, 'national', '{}.csv'.format(c)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
