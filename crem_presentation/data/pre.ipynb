{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation for CECP CoP21 website\n",
    "File locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GDX_DIR = 'gdx'\n",
    "OUT_DIR = '../../../cecp-cop21-data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Run C-REM\n",
    "Run the next cell will run the model eight times, which takes a *very long time*. The commands are provided for illustration.\n",
    "\n",
    "Currently, separate commits of C-REM must be used to run the base and 'less-GDP' cases.\n",
    "\n",
    "See [issue #35](https://github.com/mit-jp/crem/issues/35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "# C-REM runs\n",
    "crem gdx/result_urban_exo -- --case=default\n",
    "crem gdx/result_cint_n_3 -- --case=cint_n --cint_n_rate=3\n",
    "crem gdx/result_cint_n_4 -- --case=cint_n --cint_n_rate=4\n",
    "crem gdx/result_cint_n_5 -- --case=cint_n --cint_n_rate=5\n",
    "# Low-growth cases\n",
    "crem gdx/result_urban_exo_lessGDP -- --case=default\n",
    "crem gdx/result_cint_n_3_lessGDP -- --case=cint_n --cint_n_rate=3\n",
    "crem gdx/result_cint_n_4_lessGDP -- --case=cint_n --cint_n_rate=4\n",
    "crem gdx/result_cint_n_5_lessGDP -- --case=cint_n --cint_n_rate=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preprocess the GDX files\n",
    "Some of the quantities used below are stored in the GAMS parameters `report(*,*,*)` and `egyreport2(*,*,*,*)`, which pyGDX cannot handle. The cell below runs the simple GAMS script `pre.gms` to produce a new file named `*foo*_extra.gdx` with the pyGDX-friendly variables `ptcarb_t(t)`, `pe_t(e,r,t)` and `cons_t(r,t)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "gams pre.gms --file=gdx/result_urban_exo\n",
    "gams pre.gms --file=gdx/result_cint_n_3\n",
    "gams pre.gms --file=gdx/result_cint_n_4\n",
    "gams pre.gms --file=gdx/result_cint_n_5\n",
    "gams pre.gms --file=gdx/result_urban_exo_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_3_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_4_lessGDP\n",
    "gams pre.gms --file=gdx/result_cint_n_5_lessGDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Read the GDX files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load all the GDX files\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from os import makedirs as mkdir\n",
    "from os.path import join\n",
    "\n",
    "import gdx\n",
    "from openpyxl import load_workbook\n",
    "import pandas as pd\n",
    "import xray\n",
    "\n",
    "FILES = [\n",
    "    ('bau', 'result_urban_exo.gdx'),\n",
    "    ('3', 'result_cint_n_3.gdx'),\n",
    "    ('4', 'result_cint_n_4.gdx'),\n",
    "    ('5', 'result_cint_n_5.gdx'),\n",
    "    ('bau_lo', 'result_urban_exo_lessGDP.gdx'),\n",
    "    ('3_lo', 'result_cint_n_3_lessGDP.gdx'),\n",
    "    ('4_lo', 'result_cint_n_4_lessGDP.gdx'),\n",
    "    ('5_lo', 'result_cint_n_5_lessGDP.gdx'),\n",
    "    ]\n",
    "\n",
    "raw = OrderedDict()\n",
    "extra = dict()\n",
    "for case, fn in FILES:\n",
    "    raw[case] = gdx.File('gdx/' + fn)\n",
    "    extra[case] = gdx.File('gdx/' + fn.replace('.gdx', '_extra.gdx'))\n",
    "\n",
    "CREM = raw['bau']\n",
    "cases = pd.Index(raw.keys(), name='case')\n",
    "time = pd.Index(filter(lambda t: int(t) <= 2030, CREM.set('t')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List all the parameters available in each file\n",
    "#CREM.parameters()\n",
    "\n",
    "# Temporary container for read-in data\n",
    "arrays = {}\n",
    "\n",
    "def label(variable, desc, unit_long, unit_short):\n",
    "    \"\"\"Add some descriptive attributes to an xray.DataArray.\"\"\"\n",
    "    arrays[variable].attrs.update({'desc': desc, 'unit_long': unit_long,\n",
    "                                   'unit_short': unit_short})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# GDP\n",
    "temp = [raw[case].extract('gdp_ref') for case in cases]\n",
    "arrays['GDP'] = xray.concat(temp, dim=cases).sel(rs=CREM.set('r')) \\\n",
    "                    .rename({'rs': 'r'})\n",
    "label('GDP', 'Gross domestic product',\n",
    "      'billions of U.S. dollars, constant at 2007', '10⁹ USD')\n",
    "arrays['GDP_delta'] = (arrays['GDP'] / arrays['GDP'].sel(case='bau') - 1) * 100\n",
    "label('GDP_delta', 'Change in gross domestic product relative to BAU',\n",
    "      'percent', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CO2 emissions\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('sectem').sum('g') +\n",
    "        raw[case].extract('houem'))\n",
    "arrays['CO2_emi'] = xray.concat(temp, dim=cases)\n",
    "label('CO2_emi', 'Annual CO₂ emissions',\n",
    "      'millions of tonnes of CO₂', 'Mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Air pollutant emissions\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('urban').sum('*'))\n",
    "temp = xray.concat(temp, dim=cases).sel(rs=CREM.set('r')).rename({'rs': 'r'})\n",
    "for u in temp['urb']:\n",
    "    if u in ['PM10', 'PM25']:\n",
    "        continue\n",
    "    var_name = '{}_emi'.format(u.values)\n",
    "    arrays[var_name] = temp.sel(urb=u).drop('urb')\n",
    "    u_fancy = str(u.values).translate({'2': '₂', '3': '₃'})\n",
    "    label(var_name, 'Annual {} emissions'.format(u_fancy),\n",
    "          'millions of tonnes of ' + str(u_fancy), 'Mt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CO₂ price\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('ptcarb_t'))\n",
    "arrays['CO2_price'] = xray.concat(temp, dim=cases)\n",
    "label('CO2_price', 'Price of CO₂ emissions permit',\n",
    "      '2007 US dollars per tonne CO₂', '2007 USD/t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Consumption\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('cons_t'))\n",
    "arrays['cons'] = xray.concat(temp, dim=cases)\n",
    "label('cons', 'Household consumption',\n",
    "      'billions of U.S. dollars, constant at 2007', '10⁹ USD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Primary energy\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(extra[case].extract('pe_t'))\n",
    "temp = xray.concat(temp, dim=cases)\n",
    "temp = temp.where(temp < 1e300).fillna(0)\n",
    "e_name = {\n",
    "    'COL': 'Coal',\n",
    "    'GAS': 'Natural gas',\n",
    "    'OIL': 'Crude oil',\n",
    "    'NUC': 'Nuclear',\n",
    "    'WND': 'Wind',\n",
    "    'SOL': 'Solar',\n",
    "    'HYD': 'Hydroelectricity',\n",
    "    }\n",
    "for ener in temp['e']:\n",
    "    var_name = '{}_energy'.format(ener.values)\n",
    "    arrays[var_name] = temp.sel(e=ener).drop('e')\n",
    "    label(var_name, 'Primary energy from {}'.format(e_name[str(ener.values)]),\n",
    "          'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "# Sums and shares \n",
    "arrays['energy_total'] = temp.sum('e')\n",
    "label('energy_total', 'Primary energy, total',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['energy_fossil'] = temp.sel(e=['COL', 'GAS', 'OIL']).sum('e')\n",
    "label('energy_fossil', 'Primary energy from fossil fuels',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['energy_nonfossil'] = temp.sel(e=['NUC', 'WND', 'SOL', 'HYD']).sum('e')\n",
    "label('energy_nonfossil', 'Primary energy from non-fossil sources',\n",
    "      'millions of tonnes of coal equivalent', 'Mtce')\n",
    "\n",
    "arrays['energy_nonfossil_share'] = (arrays['energy_nonfossil'] /\n",
    "    arrays['energy_total']) * 100\n",
    "label('energy_nonfossil_share', 'Share of non-fossil sources in primary energy',\n",
    "      'percent', '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<xray.DataArray 'pe_t' (t: 10)>\n",
       "array([  4.82483529,   3.72598328,   4.66794189,   6.43244279,\n",
       "        10.13062321,  17.13947095,          nan,          nan,\n",
       "                nan,          nan])\n",
       "Coordinates:\n",
       "  * t        (t) <U4 '2007' '2010' '2015' '2020' '2025' '2030' '2035' '2040' ...\n",
       "    case     object 'bau'\n",
       "    r        <U2 'GD'\n",
       "Attributes:\n",
       "    unit_short: %\n",
       "    unit_long: percent\n",
       "    desc: Share of non-fossil sources in primary energy"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arrays['energy_nonfossil_share'].sel(case='bau', r='GD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Population\n",
    "temp = []\n",
    "for case in cases:\n",
    "    temp.append(raw[case].extract('pop2007').sel(g='c') *\n",
    "                raw[case].extract('pop') * 1e-2)\n",
    "arrays['pop'] = xray.concat(temp, dim=cases).drop('g').sel(rs=CREM.set('r')) \\\n",
    "                    .rename({'rs': 'r'})\n",
    "label('pop', 'Population', 'millions', '10⁶')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Share of coal in production inputs\n",
    "temp = []\n",
    "for case in cases:\n",
    "    y_in = raw[case].extract('sect_input')\n",
    "    e_in = raw[case].extract('ye_input')\n",
    "    nhw_in = raw[case].extract('ynhw_input')\n",
    "    # Total coal input\n",
    "    COL = y_in.sum('g').sel(**{'*': 'COL'}) + e_in.sel(**{'*': 'COL'})\n",
    "    # Total of ELE inputs, to avoid double-counting\n",
    "    ELE_in = e_in.sum('*') + nhw_in.sum('*')\n",
    "    temp.append(COL / (y_in.sum(['*', 'g']) - ELE_in))\n",
    "arrays['COL_share'] = xray.concat(temp, dim=cases).drop('*') \\\n",
    "                          .sel(rs=CREM.set('r')).rename({'rs': 'r'})\n",
    "label('COL_share', 'Value share of coal in industrial production',\n",
    "      '(unitless)', '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PM2.5 population-weighted exposure\n",
    "**Note:** these are contained in a separate XLSX file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Open the workbook and worksheet\n",
    "wb = load_workbook('pm.xlsx', read_only=True)\n",
    "ws = wb['Sheet1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read the table in to a list of lists\n",
    "temp = []\n",
    "cols = {\n",
    "    None: 'None',\n",
    "    2010: ('bau', '2010'),\n",
    "    2030: ('bau', '2030'),\n",
    "    '2030_p2': ('2', '2030'),\n",
    "    '2030_p3': ('3', '2030'),\n",
    "    '2030_p4': ('4', '2030'),\n",
    "    '2030_p5': ('5', '2030'),\n",
    "    '2030_p6': ('6', '2030'),\n",
    "    }\n",
    "for r, row in enumerate(ws.rows):\n",
    "    if r < 1 or r > 31:\n",
    "        pass\n",
    "    elif r == 1:\n",
    "        temp.append([cols[cell.value] for c, cell in enumerate(row) if c < 8])\n",
    "    else:\n",
    "        temp.append([cell.value for c, cell in enumerate(row) if c < 8])\n",
    "\n",
    "# Convert to a pandas.DataFrame\n",
    "df = pd.DataFrame(temp).set_index(0)\n",
    "df.columns = pd.MultiIndex.from_tuples(df.iloc[0,:], names=['case', 't'])\n",
    "df.drop('None', inplace=True)\n",
    "df.index.name = 'r'\n",
    "df = df.stack(['case', 't']).swaplevel('case', 'r')\n",
    "\n",
    "# Convert to an xray.DataArray\n",
    "da = xray.DataArray.from_series(df)\n",
    "# Fill in 2010 values across cases\n",
    "for c in da.coords['case']:\n",
    "    da.loc[c,:,'2010'] = da.loc['bau',:,'2010']\n",
    "arrays['PM25_exposure'] = da.drop(['2', '6'], dim='case')\n",
    "label('PM25_exposure', 'Population-weighted exposure to PM2.5',\n",
    "      'micrograms per cubic metre', 'μg/m³')\n",
    "\n",
    "# TODO PM2.5 concentrations\n",
    "# FIXME this is a placeholder\n",
    "arrays['PM25_conc'] = arrays['PM25_exposure']\n",
    "label('PM25_conc', 'Province-wide average PM2.5',\n",
    "      'micrograms per cubic metre', 'μg/m³')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine all variables into a single xray.Dataset and truncate time\n",
    "data = xray.Dataset(arrays).sel(t=time)\n",
    "\n",
    "data['scenarios'] = xray.DataArray((\n",
    "    'BAU: Business-as-usual',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 3%/year from BAU',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 4%/year from BAU',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 5%/year from BAU',\n",
    "    'LO: BAU with 1% lower annual GDP growth',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 3%/year from LO',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 4%/year from LO',\n",
    "    'Policy: Reduce carbon-intensity of GDP by 5%/year from LO',\n",
    "    ), coords={'case': cases}, dims='case')\n",
    "\n",
    "for var in [data.PM25_exposure, data.PM25_conc]:\n",
    "    # FIXME fill in PM data for missing years\n",
    "    var.loc[:,:,'2007'] = var.loc[:,:,'2010'] * 0.5\n",
    "    var.loc[:,:,'2015'] = var.loc[:,:,'2030'] * 1.5\n",
    "    var.loc[:,:,'2020'] = var.loc[:,:,'2030'] * 1.5\n",
    "    var.loc[:,:,'2025'] = var.loc[:,:,'2030'] * 1.5\n",
    "    # FIXME fill in PM data for missing cases\n",
    "    var.loc['bau_lo',:,:] = var.loc['bau',:,:] * 0.9\n",
    "    var.loc['3_lo',:,:] = var.loc['3',:,:] * 0.9\n",
    "    var.loc['4_lo',:,:] = var.loc['4',:,:] * 0.9\n",
    "    var.loc['5_lo',:,:] = var.loc['5',:,:] * 0.9\n",
    "\n",
    "# TODO construct data for low-ammonia cases\n",
    "#  - The NH3 *emissions* are not plotted; so this may not be necessary.\n",
    "base_cases = [str(name.values) for name in data['case']] \n",
    "nh3_cases = [name + '_nh3' for name in base_cases]\n",
    "d = xray.Dataset(coords={'case': nh3_cases})\n",
    "data.merge(d, join='outer', inplace=True)\n",
    "\n",
    "# FIXME fill in PM data for missing cases\n",
    "for nh3_case, base_case in zip(nh3_cases, base_cases):\n",
    "    data.PM25_conc.loc[nh3_case,:,:] = data.PM25_conc.loc[base_case,:,:]\n",
    "\n",
    "# National totals\n",
    "national = data.sum('r')\n",
    "national['energy_nonfossil_share'] = (national.energy_nonfossil /\n",
    "    national.energy_total) * 100\n",
    "# FIXME use a proper national average\n",
    "national['PM25_exposure'] = data.PM25_exposure.mean(dim='r')\n",
    "national['PM25_conc'] = data.PM25_conc.mean(dim='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing dimension info:\n"
     ]
    }
   ],
   "source": [
    "# Output a file with scenario information\n",
    "data['scenarios'].to_dataframe().to_csv(join(OUT_DIR, 'scenarios.csv'),\n",
    "                                        header=['description'],\n",
    "                                        quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Output a file with variable information\n",
    "var_info = pd.DataFrame(index=[d for d in data.data_vars if d != 'scenarios'],\n",
    "                        columns=['desc', 'unit_long', 'unit_short'],\n",
    "                       dtype=str)\n",
    "print('Missing dimension info:')\n",
    "for name, _ in var_info.iterrows():\n",
    "    try:\n",
    "        row = [data[name].attrs[k] for k in var_info.columns]\n",
    "    except KeyError:\n",
    "        print(' ', name)\n",
    "        continue\n",
    "    var_info.loc[name,:] = row\n",
    "var_info.to_csv(join(OUT_DIR, 'variables.csv'), index_label='Variable',\n",
    "                quoting=csv.QUOTE_ALL)\n",
    "\n",
    "# Create directories\n",
    "for r in CREM.set('r'):\n",
    "    mkdir(join(OUT_DIR, r), exist_ok=True)\n",
    "mkdir(join(OUT_DIR, 'national'), exist_ok=True)\n",
    "\n",
    "# Serialize to CSV\n",
    "for c in map(lambda x: x.values, data.case):\n",
    "    # Provincial data\n",
    "    for r in CREM.set('r'):\n",
    "        data.sel(case=c, r=r).drop(['case', 'r', 'scenarios']).to_dataframe()\\\n",
    "            .to_csv(join(OUT_DIR, r, '{}.csv'.format(c)))\n",
    "    # National data\n",
    "    national.sel(case=c).drop(['case', 'scenarios']).to_dataframe() \\\n",
    "            .to_csv(join(OUT_DIR, 'national', '{}.csv'.format(c)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
